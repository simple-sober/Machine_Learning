{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wheat Prediction Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Packages used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import mean_squared_error as err\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sknn.mlp import Regressor, Layer\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading and concatenating the 2013 and 2014 data to form 1 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2013 = pd.read_csv(\"wheat-2013-supervised.csv\")\n",
    "data_2014 = pd.read_csv(\"wheat-2014-supervised.csv\")\n",
    "total_data = pd.concat([data_2013, data_2014],axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the datashape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(177493, 26)\n",
      "(360042, 26)\n"
     ]
    }
   ],
   "source": [
    "print(data_2013.shape)\n",
    "print(total_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Some Extrapolatory Analysis:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/DataFlash/anaconda/lib/python3.5/site-packages/numpy/lib/function_base.py:3834: RuntimeWarning: Invalid value encountered in percentile\n",
      "  RuntimeWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>apparentTemperatureMax</th>\n",
       "      <th>apparentTemperatureMin</th>\n",
       "      <th>cloudCover</th>\n",
       "      <th>dewPoint</th>\n",
       "      <th>humidity</th>\n",
       "      <th>precipIntensity</th>\n",
       "      <th>precipIntensityMax</th>\n",
       "      <th>precipProbability</th>\n",
       "      <th>...</th>\n",
       "      <th>precipTypeIsOther</th>\n",
       "      <th>pressure</th>\n",
       "      <th>temperatureMax</th>\n",
       "      <th>temperatureMin</th>\n",
       "      <th>visibility</th>\n",
       "      <th>windBearing</th>\n",
       "      <th>windSpeed</th>\n",
       "      <th>NDVI</th>\n",
       "      <th>DayInSeason</th>\n",
       "      <th>Yield</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>177493.000000</td>\n",
       "      <td>177493.000000</td>\n",
       "      <td>177493.000000</td>\n",
       "      <td>177493.000000</td>\n",
       "      <td>177493.000000</td>\n",
       "      <td>177493.000000</td>\n",
       "      <td>177493.000000</td>\n",
       "      <td>177492.000000</td>\n",
       "      <td>177492.000000</td>\n",
       "      <td>177492.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>177493.0</td>\n",
       "      <td>177239.000000</td>\n",
       "      <td>177493.000000</td>\n",
       "      <td>177493.000000</td>\n",
       "      <td>177463.000000</td>\n",
       "      <td>177493.000000</td>\n",
       "      <td>177493.000000</td>\n",
       "      <td>177493.000000</td>\n",
       "      <td>177493.000000</td>\n",
       "      <td>177493.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>37.525355</td>\n",
       "      <td>-100.877849</td>\n",
       "      <td>54.836240</td>\n",
       "      <td>27.915526</td>\n",
       "      <td>0.071478</td>\n",
       "      <td>29.712311</td>\n",
       "      <td>0.593973</td>\n",
       "      <td>0.001158</td>\n",
       "      <td>0.010633</td>\n",
       "      <td>0.133540</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1017.077664</td>\n",
       "      <td>57.547801</td>\n",
       "      <td>34.393113</td>\n",
       "      <td>9.285829</td>\n",
       "      <td>191.165483</td>\n",
       "      <td>8.436830</td>\n",
       "      <td>146.346701</td>\n",
       "      <td>92.633084</td>\n",
       "      <td>31.443024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.918148</td>\n",
       "      <td>5.960510</td>\n",
       "      <td>23.827278</td>\n",
       "      <td>22.029381</td>\n",
       "      <td>0.138932</td>\n",
       "      <td>16.687710</td>\n",
       "      <td>0.163590</td>\n",
       "      <td>0.004559</td>\n",
       "      <td>0.044782</td>\n",
       "      <td>0.253416</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.607401</td>\n",
       "      <td>20.755273</td>\n",
       "      <td>17.801718</td>\n",
       "      <td>1.281721</td>\n",
       "      <td>104.103600</td>\n",
       "      <td>4.767758</td>\n",
       "      <td>10.130267</td>\n",
       "      <td>53.608768</td>\n",
       "      <td>15.214107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>27.803015</td>\n",
       "      <td>-120.914093</td>\n",
       "      <td>-39.970000</td>\n",
       "      <td>-58.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-36.090000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>942.490000</td>\n",
       "      <td>-22.000000</td>\n",
       "      <td>-39.790000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>34.135464</td>\n",
       "      <td>-101.294945</td>\n",
       "      <td>37.830000</td>\n",
       "      <td>14.310000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.600000</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.350000</td>\n",
       "      <td>23.420000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>127.000000</td>\n",
       "      <td>4.760000</td>\n",
       "      <td>137.876236</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>17.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>36.810364</td>\n",
       "      <td>-99.128028</td>\n",
       "      <td>58.880000</td>\n",
       "      <td>26.560000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>27.850000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58.880000</td>\n",
       "      <td>33.250000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>192.000000</td>\n",
       "      <td>7.670000</td>\n",
       "      <td>147.225510</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>31.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>38.945878</td>\n",
       "      <td>-97.352044</td>\n",
       "      <td>73.100000</td>\n",
       "      <td>42.200000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>38.890000</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>73.100000</td>\n",
       "      <td>46.070000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>275.000000</td>\n",
       "      <td>11.530000</td>\n",
       "      <td>152.935913</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>43.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>48.981928</td>\n",
       "      <td>-94.613571</td>\n",
       "      <td>177.320000</td>\n",
       "      <td>77.180000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>75.180000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.152900</td>\n",
       "      <td>2.054900</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1048.130000</td>\n",
       "      <td>105.200000</td>\n",
       "      <td>77.180000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>359.000000</td>\n",
       "      <td>31.730000</td>\n",
       "      <td>206.000000</td>\n",
       "      <td>185.000000</td>\n",
       "      <td>72.200000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Latitude      Longitude  apparentTemperatureMax  \\\n",
       "count  177493.000000  177493.000000           177493.000000   \n",
       "mean       37.525355    -100.877849               54.836240   \n",
       "std         4.918148       5.960510               23.827278   \n",
       "min        27.803015    -120.914093              -39.970000   \n",
       "25%        34.135464    -101.294945               37.830000   \n",
       "50%        36.810364     -99.128028               58.880000   \n",
       "75%        38.945878     -97.352044               73.100000   \n",
       "max        48.981928     -94.613571              177.320000   \n",
       "\n",
       "       apparentTemperatureMin     cloudCover       dewPoint       humidity  \\\n",
       "count           177493.000000  177493.000000  177493.000000  177493.000000   \n",
       "mean                27.915526       0.071478      29.712311       0.593973   \n",
       "std                 22.029381       0.138932      16.687710       0.163590   \n",
       "min                -58.420000       0.000000     -36.090000       0.080000   \n",
       "25%                 14.310000       0.000000      19.600000       0.470000   \n",
       "50%                 26.560000       0.010000      27.850000       0.600000   \n",
       "75%                 42.200000       0.090000      38.890000       0.720000   \n",
       "max                 77.180000       1.000000      75.180000       1.000000   \n",
       "\n",
       "       precipIntensity  precipIntensityMax  precipProbability      ...        \\\n",
       "count    177492.000000       177492.000000      177492.000000      ...         \n",
       "mean          0.001158            0.010633           0.133540      ...         \n",
       "std           0.004559            0.044782           0.253416      ...         \n",
       "min           0.000000            0.000000           0.000000      ...         \n",
       "25%                NaN                 NaN                NaN      ...         \n",
       "50%                NaN                 NaN                NaN      ...         \n",
       "75%                NaN                 NaN                NaN      ...         \n",
       "max           0.152900            2.054900           0.960000      ...         \n",
       "\n",
       "       precipTypeIsOther       pressure  temperatureMax  temperatureMin  \\\n",
       "count           177493.0  177239.000000   177493.000000   177493.000000   \n",
       "mean                 0.0    1017.077664       57.547801       34.393113   \n",
       "std                  0.0       8.607401       20.755273       17.801718   \n",
       "min                  0.0     942.490000      -22.000000      -39.790000   \n",
       "25%                  0.0            NaN       43.350000       23.420000   \n",
       "50%                  0.0            NaN       58.880000       33.250000   \n",
       "75%                  0.0            NaN       73.100000       46.070000   \n",
       "max                  0.0    1048.130000      105.200000       77.180000   \n",
       "\n",
       "          visibility    windBearing      windSpeed           NDVI  \\\n",
       "count  177463.000000  177493.000000  177493.000000  177493.000000   \n",
       "mean        9.285829     191.165483       8.436830     146.346701   \n",
       "std         1.281721     104.103600       4.767758      10.130267   \n",
       "min         0.600000       0.000000       0.040000     117.000000   \n",
       "25%              NaN     127.000000       4.760000     137.876236   \n",
       "50%              NaN     192.000000       7.670000     147.225510   \n",
       "75%              NaN     275.000000      11.530000     152.935913   \n",
       "max        10.000000     359.000000      31.730000     206.000000   \n",
       "\n",
       "         DayInSeason          Yield  \n",
       "count  177493.000000  177493.000000  \n",
       "mean       92.633084      31.443024  \n",
       "std        53.608768      15.214107  \n",
       "min         0.000000       9.000000  \n",
       "25%        46.000000      17.300000  \n",
       "50%        93.000000      31.100000  \n",
       "75%       139.000000      43.100000  \n",
       "max       185.000000      72.200000  \n",
       "\n",
       "[8 rows x 23 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_2013.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountyName                 object\n",
       "State                      object\n",
       "Latitude                  float64\n",
       "Longitude                 float64\n",
       "Date                       object\n",
       "apparentTemperatureMax    float64\n",
       "apparentTemperatureMin    float64\n",
       "cloudCover                float64\n",
       "dewPoint                  float64\n",
       "humidity                  float64\n",
       "precipIntensity           float64\n",
       "precipIntensityMax        float64\n",
       "precipProbability         float64\n",
       "precipAccumulation        float64\n",
       "precipTypeIsRain            int64\n",
       "precipTypeIsSnow            int64\n",
       "precipTypeIsOther           int64\n",
       "pressure                  float64\n",
       "temperatureMax            float64\n",
       "temperatureMin            float64\n",
       "visibility                float64\n",
       "windBearing                 int64\n",
       "windSpeed                 float64\n",
       "NDVI                      float64\n",
       "DayInSeason                 int64\n",
       "Yield                     float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_2013.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/DataFlash/anaconda/lib/python3.5/site-packages/numpy/lib/function_base.py:3834: RuntimeWarning: Invalid value encountered in percentile\n",
      "  RuntimeWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>apparentTemperatureMax</th>\n",
       "      <th>apparentTemperatureMin</th>\n",
       "      <th>cloudCover</th>\n",
       "      <th>dewPoint</th>\n",
       "      <th>humidity</th>\n",
       "      <th>precipIntensity</th>\n",
       "      <th>precipIntensityMax</th>\n",
       "      <th>precipProbability</th>\n",
       "      <th>...</th>\n",
       "      <th>precipTypeIsOther</th>\n",
       "      <th>pressure</th>\n",
       "      <th>temperatureMax</th>\n",
       "      <th>temperatureMin</th>\n",
       "      <th>visibility</th>\n",
       "      <th>windBearing</th>\n",
       "      <th>windSpeed</th>\n",
       "      <th>NDVI</th>\n",
       "      <th>DayInSeason</th>\n",
       "      <th>Yield</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>182549.000000</td>\n",
       "      <td>182549.000000</td>\n",
       "      <td>182549.000000</td>\n",
       "      <td>182549.000000</td>\n",
       "      <td>182549.000000</td>\n",
       "      <td>182549.000000</td>\n",
       "      <td>182549.000000</td>\n",
       "      <td>182549.000000</td>\n",
       "      <td>182549.000000</td>\n",
       "      <td>182549.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>182549.0</td>\n",
       "      <td>182198.000000</td>\n",
       "      <td>182549.000000</td>\n",
       "      <td>182549.000000</td>\n",
       "      <td>182533.000000</td>\n",
       "      <td>182549.000000</td>\n",
       "      <td>182549.000000</td>\n",
       "      <td>182549.000000</td>\n",
       "      <td>182549.00000</td>\n",
       "      <td>182549.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>36.976937</td>\n",
       "      <td>-100.547088</td>\n",
       "      <td>57.146379</td>\n",
       "      <td>33.669343</td>\n",
       "      <td>0.131278</td>\n",
       "      <td>36.664752</td>\n",
       "      <td>0.680338</td>\n",
       "      <td>0.002501</td>\n",
       "      <td>0.021390</td>\n",
       "      <td>0.205662</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1018.779783</td>\n",
       "      <td>58.989567</td>\n",
       "      <td>38.757876</td>\n",
       "      <td>9.042049</td>\n",
       "      <td>171.727963</td>\n",
       "      <td>7.595578</td>\n",
       "      <td>145.885753</td>\n",
       "      <td>92.65286</td>\n",
       "      <td>33.836357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.926798</td>\n",
       "      <td>5.587446</td>\n",
       "      <td>20.217840</td>\n",
       "      <td>19.649074</td>\n",
       "      <td>0.170087</td>\n",
       "      <td>16.202934</td>\n",
       "      <td>0.150459</td>\n",
       "      <td>0.007232</td>\n",
       "      <td>0.071354</td>\n",
       "      <td>0.307787</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.753283</td>\n",
       "      <td>17.404119</td>\n",
       "      <td>15.739407</td>\n",
       "      <td>1.473647</td>\n",
       "      <td>102.727345</td>\n",
       "      <td>4.072584</td>\n",
       "      <td>10.335488</td>\n",
       "      <td>53.63330</td>\n",
       "      <td>10.630116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>27.363741</td>\n",
       "      <td>-120.914093</td>\n",
       "      <td>-24.340000</td>\n",
       "      <td>-43.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-21.950000</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>945.090000</td>\n",
       "      <td>-5.570000</td>\n",
       "      <td>-24.960000</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>12.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>33.598030</td>\n",
       "      <td>-101.174610</td>\n",
       "      <td>41.390000</td>\n",
       "      <td>20.890000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>25.740000</td>\n",
       "      <td>0.570000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.850000</td>\n",
       "      <td>28.390000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>4.490000</td>\n",
       "      <td>136.480255</td>\n",
       "      <td>46.00000</td>\n",
       "      <td>25.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>36.164529</td>\n",
       "      <td>-99.068063</td>\n",
       "      <td>61.460000</td>\n",
       "      <td>33.310000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>35.130000</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61.460000</td>\n",
       "      <td>38.510000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>171.000000</td>\n",
       "      <td>7.090000</td>\n",
       "      <td>146.507538</td>\n",
       "      <td>93.00000</td>\n",
       "      <td>32.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>38.451644</td>\n",
       "      <td>-97.270576</td>\n",
       "      <td>72.990000</td>\n",
       "      <td>50.630000</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>48.840000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.010100</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72.990000</td>\n",
       "      <td>50.630000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>246.000000</td>\n",
       "      <td>10.150000</td>\n",
       "      <td>153.231476</td>\n",
       "      <td>139.00000</td>\n",
       "      <td>41.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>48.981928</td>\n",
       "      <td>-94.164602</td>\n",
       "      <td>103.910000</td>\n",
       "      <td>79.560000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>78.350000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.255800</td>\n",
       "      <td>3.367400</td>\n",
       "      <td>0.970000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1049.530000</td>\n",
       "      <td>95.580000</td>\n",
       "      <td>79.560000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>359.000000</td>\n",
       "      <td>30.460000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>185.00000</td>\n",
       "      <td>78.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Latitude      Longitude  apparentTemperatureMax  \\\n",
       "count  182549.000000  182549.000000           182549.000000   \n",
       "mean       36.976937    -100.547088               57.146379   \n",
       "std         4.926798       5.587446               20.217840   \n",
       "min        27.363741    -120.914093              -24.340000   \n",
       "25%        33.598030    -101.174610               41.390000   \n",
       "50%        36.164529     -99.068063               61.460000   \n",
       "75%        38.451644     -97.270576               72.990000   \n",
       "max        48.981928     -94.164602              103.910000   \n",
       "\n",
       "       apparentTemperatureMin     cloudCover       dewPoint       humidity  \\\n",
       "count           182549.000000  182549.000000  182549.000000  182549.000000   \n",
       "mean                33.669343       0.131278      36.664752       0.680338   \n",
       "std                 19.649074       0.170087      16.202934       0.150459   \n",
       "min                -43.250000       0.000000     -21.950000       0.140000   \n",
       "25%                 20.890000       0.010000      25.740000       0.570000   \n",
       "50%                 33.310000       0.080000      35.130000       0.680000   \n",
       "75%                 50.630000       0.180000      48.840000       0.800000   \n",
       "max                 79.560000       1.000000      78.350000       1.000000   \n",
       "\n",
       "       precipIntensity  precipIntensityMax  precipProbability      ...        \\\n",
       "count    182549.000000       182549.000000      182549.000000      ...         \n",
       "mean          0.002501            0.021390           0.205662      ...         \n",
       "std           0.007232            0.071354           0.307787      ...         \n",
       "min           0.000000            0.000000           0.000000      ...         \n",
       "25%           0.000000            0.000000           0.000000      ...         \n",
       "50%           0.000000            0.000000           0.000000      ...         \n",
       "75%           0.001000            0.010100           0.510000      ...         \n",
       "max           0.255800            3.367400           0.970000      ...         \n",
       "\n",
       "       precipTypeIsOther       pressure  temperatureMax  temperatureMin  \\\n",
       "count           182549.0  182198.000000   182549.000000   182549.000000   \n",
       "mean                 0.0    1018.779783       58.989567       38.757876   \n",
       "std                  0.0       7.753283       17.404119       15.739407   \n",
       "min                  0.0     945.090000       -5.570000      -24.960000   \n",
       "25%                  0.0            NaN       45.850000       28.390000   \n",
       "50%                  0.0            NaN       61.460000       38.510000   \n",
       "75%                  0.0            NaN       72.990000       50.630000   \n",
       "max                  0.0    1049.530000       95.580000       79.560000   \n",
       "\n",
       "          visibility    windBearing      windSpeed           NDVI  \\\n",
       "count  182533.000000  182549.000000  182549.000000  182549.000000   \n",
       "mean        9.042049     171.727963       7.595578     145.885753   \n",
       "std         1.473647     102.727345       4.072584      10.335488   \n",
       "min         0.460000       0.000000       0.020000     101.000000   \n",
       "25%              NaN      89.000000       4.490000     136.480255   \n",
       "50%              NaN     171.000000       7.090000     146.507538   \n",
       "75%              NaN     246.000000      10.150000     153.231476   \n",
       "max        10.000000     359.000000      30.460000     208.000000   \n",
       "\n",
       "        DayInSeason          Yield  \n",
       "count  182549.00000  182549.000000  \n",
       "mean       92.65286      33.836357  \n",
       "std        53.63330      10.630116  \n",
       "min         0.00000      12.900000  \n",
       "25%        46.00000      25.700000  \n",
       "50%        93.00000      32.900000  \n",
       "75%       139.00000      41.500000  \n",
       "max       185.00000      78.000000  \n",
       "\n",
       "[8 rows x 23 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_2014.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We are removing the location based data because the yield for a particular location is always the same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** Hypothesis 1 **: \n",
    "A particular location (Longitude, Latitude) always have the same yield throughout a particular winter wheat yield, the Yield is different for different winters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First rounding the latitude and longitude\n",
    "data_2013[['Latitude','Longitude']] = data_2013[['Latitude','Longitude']].round(6)\n",
    "data_2014[['Latitude','Longitude']] = data_2014[['Latitude','Longitude']].round(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>46.811686</td>\n",
       "      <td>-118.695237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>46.929839</td>\n",
       "      <td>-118.352109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>47.006888</td>\n",
       "      <td>-118.510160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>47.162342</td>\n",
       "      <td>-118.699677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>47.157512</td>\n",
       "      <td>-118.434056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index   Latitude   Longitude\n",
       "0      0  46.811686 -118.695237\n",
       "1      1  46.929839 -118.352109\n",
       "2      2  47.006888 -118.510160\n",
       "3      3  47.162342 -118.699677\n",
       "4      4  47.157512 -118.434056"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a dataframe for unique combinations of latitude and longitude\n",
    "lon_lat13 = data_2013.drop_duplicates(['Latitude','Longitude']).ix[:,2:4]\n",
    "lon_lat13 = lon_lat13.reset_index(inplace=False)\n",
    "lon_lat13.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of coordinates with more than 1 yield value: 0.0000 \n",
      "Total number of coordinates: 1014.0000\n"
     ]
    }
   ],
   "source": [
    "yield_list = []\n",
    "num_diff_yield = []\n",
    "for i in range(0, len(lon_lat13)):\n",
    "        yield_list.append(data_2013[(data_2013.Latitude == lon_lat13.Latitude[i]) &\n",
    "                                    (data_2013.Longitude == lon_lat13.Longitude[i])].Yield.unique())\n",
    "        num_diff_yield.append(len(data_2013[(data_2013.Latitude == lon_lat13.Latitude[i]) &\n",
    "                                            (data_2013.Longitude == lon_lat13.Longitude[i])].Yield.unique()))\n",
    "\n",
    "df1 = pd.DataFrame({'Location' : list(zip(lon_lat13.Latitude, lon_lat13.Longitude)), \n",
    "                   'Unique_Yields' : yield_list, 'Number_yield': num_diff_yield}, \n",
    "                  columns= ['Location','Unique_Yields', 'Number_yield'])\n",
    "\n",
    "print(\"Number of coordinates with more than 1 yield value: %.4f \" % len(df1[df1.Number_yield > 1]))\n",
    "print(\"Total number of coordinates: %.4f\" %len(df1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hypothesis 2:\n",
    "Mostly particular county always produce the same yield throughout a particular winter year but the value of Yield is different for different years\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of counties with more than 1 yield value: 19.0000 \n",
      "Total number of counties: 150.0000\n",
      "       County Unique_Yields  Number_yield\n",
      "0       Adams        [35.7]             1\n",
      "1     Alfalfa        [14.4]             1\n",
      "2       Allen        [46.5]             1\n",
      "3    Anderson        [45.6]             1\n",
      "4      Archer        [13.1]             1\n",
      "5   Armstrong        [13.8]             1\n",
      "6      Asotin        [52.4]             1\n",
      "7    Atchison        [52.9]             1\n",
      "8      Bailey        [21.4]             1\n",
      "9      Barber        [13.3]             1\n",
      "10     Barton        [27.6]             1\n",
      "11     Baylor        [16.5]             1\n",
      "12     Beaver        [14.6]             1\n",
      "13    Beckham        [14.2]             1\n",
      "14       Bell        [52.2]             1\n",
      "15      Bexar        [31.5]             1\n",
      "16   Big Horn        [52.4]             1\n",
      "17     Blaine  [38.4, 18.1]             2\n",
      "18     Bosque        [27.1]             1\n",
      "19    Bourbon        [47.4]             1\n"
     ]
    }
   ],
   "source": [
    "# creating unique county list\n",
    "countynames= data_2013.CountyName.unique()\n",
    "# creating unique yields for each county\n",
    "Yield_list = []\n",
    "Num_diff_yields = []\n",
    "for county in countynames:\n",
    "    Yield_list.append(data_2013[data_2013.CountyName == county].Yield.unique())\n",
    "    Num_diff_yields.append(len(data_2013[data_2013.CountyName == county].Yield.unique()))\n",
    "df = pd.DataFrame({'County' : countynames, 'Unique_Yields' : Yield_list, 'Number_yield': Num_diff_yields}, \n",
    "                  columns= ['County','Unique_Yields', 'Number_yield'])\n",
    "\n",
    "print(\"Number of counties with more than 1 yield value: %.4f \" % len(df[df.Number_yield > 1]))\n",
    "print(\"Total number of counties: %.4f\" %len(df))\n",
    "print(df.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing location based fields in the data i.e. CountyName, State, Latitude and Longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_data1 = total_data.drop(['CountyName','State','Latitude','Longitude','Date'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing the rows with 'NA' values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_data2 = total_data1.dropna(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360042\n",
      "359427\n"
     ]
    }
   ],
   "source": [
    "# number of rows before and after removing 'na' values\n",
    "print(total_data1.shape[0])\n",
    "print(total_data2.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separating the Feature space and target value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = list(total_data2.columns)\n",
    "cols.remove('Yield')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a Train and Test split from the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_split, test_split = train_test_split(total_data2, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Creation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Technical Choice #1:\n",
    "We start with a Tree based model rather than a linear model as when the relationship between a feature and the output is conditional upon the values of other features. A tree-based model would be able to capture such a conditionality, but linear models simply cannot.\n",
    "\n",
    "Also, Tree-based models in principle can approximate functions with any \"shape\", whereas linear models can only produce functions with a linear \"shape\" with respect to a chosen set of features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 1: RandomForest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# instantiating the model\n",
    "rf_model = RandomForestRegressor(n_estimators=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Technical Choice #2:\n",
    "'n_estimators': The number of trees in the forest\n",
    "                As the number of trees increases the complexity, time taken to run the model increases but the errors                 decreases. But with higher number of trees the model can overfit. Therefore the number of trees should                 be optimal i.e to maintain balance between reduced error and overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting the model\n",
    "rf_model.fit(X=train_split.ix[:,cols],y=train_split.ix[:,'Yield'])\n",
    "\n",
    "# important features\n",
    "imp = list(zip(cols,rf_model.feature_importances_))\n",
    "imp=sorted(imp,key=lambda x:x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('precipTypeIsOther', 0.0), ('precipTypeIsSnow', 0.00029189168414234766), ('precipTypeIsRain', 0.0011626745261745395), ('precipAccumulation', 0.003710920565215034), ('precipProbability', 0.0077013226941761385), ('precipIntensityMax', 0.014739361083301811), ('precipIntensity', 0.016481908543440286), ('cloudCover', 0.043038495168122769), ('apparentTemperatureMax', 0.047368610314130997), ('visibility', 0.048177345727372339), ('temperatureMin', 0.050550830806836512), ('apparentTemperatureMin', 0.05859493075473942), ('temperatureMax', 0.060403921580267), ('humidity', 0.068570276870110553), ('dewPoint', 0.076327374003527459), ('windSpeed', 0.088303191707672771), ('pressure', 0.1024610111290348), ('windBearing', 0.10250849046239251), ('NDVI', 0.10431793647912092), ('DayInSeason', 0.10528950590022174)]\n"
     ]
    }
   ],
   "source": [
    "# Printing the feature importance\n",
    "print(imp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make Predictions on the Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred1 = rf_model.predict(test_split.ix[:,cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation(Metrics Used)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean Square Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 32.5445\n"
     ]
    }
   ],
   "source": [
    "error1 = err(test_split.ix[:,\"Yield\"], pred1)\n",
    "print( \"MSE: %.4f\" % error1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Technical Choice #3:\n",
    "** Metric used: Mean Square error: **\n",
    "\n",
    "Among various metrics like 'mean absolute error', median absolute error', R2 score and 'Mean squared error'. We choose\n",
    "'mean Square Error'. It refers to the mean of the squared deviation of predicted value from the true valued. It is always positive and a value closer to zero is better.\n",
    "\n",
    "Since the errors are square before they are averaged therefore, the MSE gives a relatively high weight to large errors. This means the RMSE is most useful when large errors are particularly undesirable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 2: Gradient Boosting Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Technical Choice # 4:\n",
    "The next model, we opted for is Gradient Boosting, as it concentrates on reducing the error rather than fitting trees on random samples of the data and it more robust to overfitting than radom forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "params = {'n_estimators' :600, 'learning_rate' : 0.4, 'loss' : 'ls',\n",
    "         'max_depth' : 8}\n",
    "# instantiating the model\n",
    "XGboost_model = GradientBoostingRegressor(**params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Technical Choice # 5:\n",
    "The parameters values used in the above model:\n",
    "1. 'n_estimators': The number of boosting stages to perform on the data\n",
    "2. 'learning_rate': learning rate shrinks the contribution of each tree by learning_rate. There is a trade-off between learning_rate and n_estimators.\n",
    "3. 'loss': 'ls' refers to least squares regression. It is a natural choice for regression due to its superior computational properties.\n",
    "4. 'max_depth': The maximum depth limits the number of nodes in the tree. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, init=None, learning_rate=0.4, loss='ls',\n",
       "             max_depth=8, max_features=None, max_leaf_nodes=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, n_estimators=600,\n",
       "             presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
       "             warm_start=False)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting the model\n",
    "XGboost_model.fit(train_split.ix[:,cols], train_split.ix[:,\"Yield\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions using the Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred2 = XGboost_model.predict(test_split.ix[:,cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean Squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 46.5780\n"
     ]
    }
   ],
   "source": [
    "error2 = err(test_split.ix[:,'Yield'], pred2)\n",
    "print( \"MSE: %.4f\" % error2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('precipTypeIsOther', 0.0), ('precipTypeIsSnow', 0.00033901105112699241), ('precipTypeIsRain', 0.0013632848776586864), ('precipAccumulation', 0.0053956048674925613), ('precipProbability', 0.0076111375991251623), ('precipIntensity', 0.01659487173019969), ('precipIntensityMax', 0.021069598879736175), ('cloudCover', 0.041328881504054962), ('humidity', 0.052089157903250367), ('visibility', 0.055988290604049556), ('apparentTemperatureMax', 0.060677606268600949), ('temperatureMax', 0.063116269270616157), ('apparentTemperatureMin', 0.067361294758196341), ('temperatureMin', 0.069396603261068487), ('DayInSeason', 0.078247219819457065), ('windBearing', 0.08354261915507144), ('dewPoint', 0.084507237743157534), ('windSpeed', 0.09027496538221555), ('NDVI', 0.093384015066367121), ('pressure', 0.10771233025855489)]\n"
     ]
    }
   ],
   "source": [
    "# important features \n",
    "imp2 = list(zip(cols, XGboost_model.feature_importances_))\n",
    "imp2 = sorted(imp2,key=lambda x:x[1])\n",
    "print(imp2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Technical Choice #6:\n",
    "Do get a better idea of the number of stages to boost the tree, we plot the deviance plot on the train and the testing data to get a better sense of the error at each boosting stage.\n",
    "Hypothesis: The plot(Deviance vs Boosting iterations) should follow a exponential curve, with deviance curving to a constant value with increasing number of iterations, so the point where the curve tends to be a straight line we can choose the iteration value as 'n_estimators'. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the test and train get deviance vs the boosting iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x119e3bd30>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAGJCAYAAACq49m1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11a46b828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# compute test set deviance\n",
    "test_score = np.zeros((params['n_estimators'],), dtype=np.float64)\n",
    "\n",
    "for i, y_pred in enumerate(XGboost_model.staged_predict(test_split.ix[:,cols])):\n",
    "    test_score[i] = XGboost_model.loss_(test_split.ix[:,\"Yield\"], y_pred)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('Deviance')\n",
    "plt.plot(np.arange(params['n_estimators']) + 1, XGboost_model.train_score_, 'b-',\n",
    "         label='Training Set Deviance')\n",
    "plt.plot(np.arange(params['n_estimators']) + 1, test_score, 'r-',\n",
    "         label='Test Set Deviance')\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel('Boosting Iterations')\n",
    "plt.ylabel('Deviance')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 3: Feed Forward Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# instantiating the model\n",
    "nn_model = Regressor(\n",
    "    layers=[\n",
    "        Layer(\"Rectifier\", units=100),\n",
    "        Layer(\"Linear\")],\n",
    "    learning_rate=0.005,\n",
    "    n_iter=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Technical Choice #7:\n",
    "1. The activation function for the hidden layer is 'Rectifier' with 100 neurons and 'linear' for the output layer\n",
    "2. The learning rate: the learning rate of backpropogation method.\n",
    "3. n_iter: The number of epoch's"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Technical Choice #8:\n",
    "1. It is best to first normalize or standardize the data before inputting it in the neural network, as standardizing the inputs can make training faster and reduce the chances of getting stuck in local optima.\n",
    "2. We need to first to remove the categorical variables (before normalizing) and then add them back after normalizing the rest of the numeric variables, as normalizing the categorical fields will make them lose their basic purpose.\n",
    "3. Also, it is always better to convert the data and response variable into a numpy array before feeding into a neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Response variable\n",
    "train_response = train_split.ix[:,\"Yield\"]\n",
    "test_response = test_split.ix[:,\"Yield\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# removing the categorical variable\n",
    "train_split_cat = train_split.ix[:, 9:12]\n",
    "test_split_cat = test_split.ix[:,9:12]\n",
    "\n",
    "# dropping the categorical variable from rest of the data\n",
    "train_split2 = train_split.drop(train_split.columns[[9,10,11,20]],axis=1)\n",
    "test_split2 = test_split.drop(train_split.columns[[9,10,11,20]],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalizing the input data\n",
    "train_split_norm = (train_split2 - train_split2.mean())/(train_split2.max() - train_split2.min())\n",
    "test_split_norm = (test_split2 - test_split2.mean())/(test_split2.max() - test_split2.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalizing the response variable\n",
    "train_response_norm = (train_response - train_response.mean())/(train_response.max() - train_response.min())\n",
    "test_response_norm = (test_response - test_response.mean())/(test_response.max() - test_response.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding the categorical variable back to the normalized data for training\n",
    "train_split_norm1 = pd.concat([train_split_norm, train_split_cat], axis=1)\n",
    "test_split_norm1 = pd.concat([test_split_norm, test_split_cat], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# converting the dataframe into a numpy array before feeding in the neural net\n",
    "Xtrain_array = train_split_norm1.ix[:,cols].as_matrix()\n",
    "ytrain_array = train_response_norm.as_matrix()\n",
    "Xtest_array = test_split_norm1.ix[:,cols].as_matrix()\n",
    "ytest_array = test_response.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Regressor(batch_size=1, callback=None, debug=False, dropout_rate=None,\n",
       "     f_stable=0.001,\n",
       "     hidden0=<sknn.nn.Layer `Rectifier`: frozen=False, name='hidden0', units=100>,\n",
       "     layers=[<sknn.nn.Layer `Rectifier`: frozen=False, name='hidden0', units=100>, <sknn.nn.Layer `Linear`: frozen=False, name='output', units=1>],\n",
       "     learning_momentum=0.9, learning_rate=0.005, learning_rule='sgd',\n",
       "     loss_type=None, n_iter=20, n_stable=10, normalize=None,\n",
       "     output=<sknn.nn.Layer `Linear`: frozen=False, name='output', units=1>,\n",
       "     parameters=None, random_state=None, regularize=None, valid_set=None,\n",
       "     valid_size=0.0, verbose=None, warning=None, weight_decay=None)"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training the model\n",
    "nn_model.fit(Xtrain_array, ytrain_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicting on the test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred3= nn_model.predict(Xtest_array)\n",
    "# denormalizing the data\n",
    "pred3_ = (pred3*(test_response.max() - test_response.min())) + test_response.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Technical Choice #9:\n",
    " I have denormalized the response variable before calculating the MSE value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean Squared Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 129.0303\n"
     ]
    }
   ],
   "source": [
    "error3 = err(ytest_array, pred3_)\n",
    "print( \"MSE: %.4f\" % error3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 4: K Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# instantiating the model\n",
    "knn_model = KNeighborsRegressor(n_neighbors= 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Technical Choice #10:\n",
    " I have used the nearest neighbors as 3(default = 5), This is chosen after performing iterations with various different values of the n_neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "          metric_params=None, n_jobs=1, n_neighbors=3, p=2,\n",
       "          weights='uniform')"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting the model\n",
    "knn_model.fit(train_split.ix[:,cols], train_split.ix[:,\"Yield\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicting on the Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred4 = knn_model.predict(test_split.ix[:,cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean Squared Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE : 41.1616\n"
     ]
    }
   ],
   "source": [
    "error4 = err(test_split.ix[:,\"Yield\"], pred4)\n",
    "print(\"MSE : %.4f\" % error4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rough Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Feature Importance\n",
    "#feature_importance = XGboost_model.feature_importances_\n",
    "# make importances relative to max importance\n",
    "#feature_importance = 100.0 * (feature_importance / feature_importance.max())\n",
    "#sorted_idx = np.argsort(feature_importance)\n",
    "#pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "#plt.subplot(1, 2, 2)\n",
    "#plt.barh(pos, feature_importance[sorted_idx], align='center')\n",
    "#plt.yticks(pos, cols[sorted_idx])  # <-- use something else than 'cols'\n",
    "#plt.xlabel('Relative Importance')\n",
    "#plt.title('Variable Importance')\n",
    "#plt.show()\n",
    "\n",
    "# incomplete"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
